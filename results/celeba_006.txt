------------------------------------------------------------------------------
celeba_006 EXPERIMENT RESULTS
------------------------------------------------------------------------------
Train configuration for that experiment was:
Epochs: 10,
 Learning rate: 0.001,
Fine tune layers: 20Loss and accuracy on train and validation set
{
  "loss": [
    7.486569404602051,
    5.038143634796143,
    4.002038955688477,
    3.414289951324463,
    3.032989740371704,
    2.7641868591308594,
    2.564854621887207,
    2.4094595909118652,
    2.2844324111938477,
    2.181570291519165
  ],
  "accuracy": [
    0.08599303662776947,
    0.2947460114955902,
    0.4131738841533661,
    0.4795430898666382,
    0.5237398743629456,
    0.5574582815170288,
    0.5811981558799744,
    0.6019821166992188,
    0.6186253428459167,
    0.632886528968811
  ],
  "val_loss": [
    6.031935214996338,
    4.857366561889648,
    4.288634300231934,
    3.9497430324554443,
    3.7465484142303467,
    3.616046905517578,
    3.5161988735198975,
    3.461282253265381,
    3.420285701751709,
    3.3847246170043945
  ],
  "val_accuracy": [
    0.17733134329319,
    0.3075396716594696,
    0.3625991940498352,
    0.3933531641960144,
    0.4097222089767456,
    0.4226190447807312,
    0.4293154776096344,
    0.4347718358039856,
    0.4357638955116272,
    0.4479166567325592
  ]
}

----------------------------------------------
On the test set the loss and accuracy was:
loss: 3.3726937770843506, 
accuracy: 0.44969242811203003
Total time for training and evaluating the model was
14387.905361890793 seconds or 239.79842269817988 minutes