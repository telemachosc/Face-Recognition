------------------------------------------------------------------------------
celeba_005 EXPERIMENT RESULTS
------------------------------------------------------------------------------
Train configuration for that experiment was:
Epochs: 10,
 Learning rate: 0.001,
Fine tune layers: 10Loss and accuracy on train and validation set
{
  "loss": [
    7.485249042510986,
    5.037926197052002,
    4.001302242279053,
    3.4134786128997803,
    3.0314738750457764,
    2.763967514038086,
    2.5632753372192383,
    2.4078867435455322,
    2.283233165740967,
    2.1833701133728027
  ],
  "accuracy": [
    0.0865299180150032,
    0.29525819420814514,
    0.41307514905929565,
    0.47999975085258484,
    0.5245853066444397,
    0.5570880174636841,
    0.5825681090354919,
    0.6024942994117737,
    0.6190881729125977,
    0.631794273853302
  ],
  "val_loss": [
    6.024895668029785,
    4.8577189445495605,
    4.294558525085449,
    3.962602376937866,
    3.7513911724090576,
    3.616325855255127,
    3.5150105953216553,
    3.473106622695923,
    3.4243311882019043,
    3.374427318572998
  ],
  "val_accuracy": [
    0.1867559552192688,
    0.2996031641960144,
    0.3608630895614624,
    0.3876488208770752,
    0.4020337164402008,
    0.4216269850730896,
    0.4283234179019928,
    0.4389880895614624,
    0.4322916567325592,
    0.4466765820980072
  ]
}

----------------------------------------------
On the test set the loss and accuracy was:
loss: 3.368225574493408, 
accuracy: 0.450488805770874
Total time for training and evaluating the model was
12140.80252957344 seconds or 202.34670882622402 minutes